---
sidebar: sidebar
permalink: solutions/cvo-aws-burst-to-cloud.html
keywords: bluexp automation catalog, netapp automation solutions, azure, burst to cloud
summary: "This article supports the NetApp Cloud Volumes ONTAP for AWS Automation Solution, which is available to NetApp customers from the BlueXP Automation Catalog."
---

= Cloud Volumes ONTAP for AWS deployment using Terraform
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/

[.lead]
This article supports the NetApp Cloud Volumes ONTAP for AWS Automation Solution, which is available to NetApp customers from the BlueXP Automation Catalog. 

The Cloud Volumes ONTAP for AWS Automation Solution automates the containerized deployment of Cloud Volumes ONTAP for AWS using Terraform, enabling you to deploy Cloud Volumes ONTAP for AWS rapidly, without any manual intervention.

.Before you begin

* You must download the link:https://console.bluexp.netapp.com/automationCatalog[CVO AWS- Burst to cloud] automation solution through the BlueXP web UI. The solution is packaged as `CVO_AWS_Deployment.zip`.
* You must install a Linux VM on the same network as Cloud Volumes ONTAP. 
* After you install the Linux VM, you must follow the steps in this solution to install the required dependencies. 

== Step 1: Install Docker and Docker Compose

=== Install Docker

The following steps use Ubuntu 20.04 Debian Linux distribution software as an example. The commands you use depend on the Linux distribution software that you are using. Refer to the specific Linux distribution software documentation for your configuration. 

.Steps

. Install Docker by running the following `sudo` commands: 
+
[source,cli]
----
sudo apt-get update 
sudo apt-get install apt-transport-https cacertificates curl gnupg-agent software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | 
sudo apt-key add -
sudo add-apt-repository “deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable” 
sudo apt-get update 
sudo apt-get install dockerce docker-ce-cli containerd.io  
----

. Verify successful installation:
+
[source,cli]
docker –version

. Check that a group named "docker" has been created on your Linux system. If necessary, create the group:
+
[source,cli]
sudo groupadd docker

. Add the user that needs to access Docker to the group:
+
[source,cli]
sudo usermod -aG docker $(whoami)

. Your changes take effect after you log out and log back in to the terminal. Alternatively, you can immediately implement the changes:
+
[source,cli]
newgrp docker

=== Install Docker Compose

.Steps 

. Install Docker Compose by running the following `sudo` commands:
+
[source,cli]
----
sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose

sudo chmod +x /usr/local/bin/docker-compose 
----
. Verify the successful installation: 
[source,cli]
docker-compose –version

== Step 2: Prepare the Docker image

.Steps
. Copy the `CVO_AWS_Deployment.zip` folder to the Linux VM that you want to use to deploy Cloud Volumes ONTAP:
+
[source,cli]
scp -i ~/<private-key>.pem -r CVO_Aws_Deployment <awsuser>@<IP_ADDRESS_OF_VM>:<LOCATION_TO_BE_COPIED> 

* `private-key.pem` is your private key file for login without a password.
* `awsuser` is the VM username.
* `IP_ADDRESS_OF_VM` is the VM IP address.
* `LOCATION_TO_BE_COPIED` is the location where the folder will be copied.

. Extract the `CVO_AWS_Deployment.zip` folder. You can extract the folder in the current directory or in a custom location.
+
To extract the folder in the current directory, run:
+
[source,cli]
unzip CVO_AWS_Deployment.zip
+
To extract the folder in a custom location, run:
+
[source,cli]
unzip CVO_AWS_Deployment.zip -d ~/<your_folder_name>

. After you extract the folder, run the following command to view the files:
+
[source,cli]
 ls -la
+
You should see a list of files, similar to the following example:
+
----
total 32
    drwxr-xr-x   8 user1  staff   256 Mar 23 12:26 .
    drwxr-xr-x   6 user1  staff   192 Mar 22 08:04 ..
    -rw-r--r--   1 user1  staff   324 Apr 12 21:37 .env
    -rw-r--r--   1 user1  staff  1449 Mar 23 13:19 Dockerfile
    drwxr-xr-x  15 user1  staff   480 Mar 23 13:19 cvo_Aws_source_code
    drwxr-xr-x   4 user1  staff   128 Apr 27 13:43 cvo_Aws_variables
    -rw-r--r--   1 user1  staff   996 Mar 24 04:06 docker-compose-deploy.yml
    -rw-r--r--   1 user1  staff  1041 Mar 24 04:06 docker-compose-destroy.yml
----
. Locate the `cvo_aws_flexcache_ubuntu_image_latest.tar.gz` file. This contains the Docker image required to deploy Cloud Volumes ONTAP for AWS.
+
Untar the file:
+
[source, cli]
docker load -i cvo_aws_flexcache_ubuntu_image_latest.tar

. Wait a few minutes for the Docker image to load, and then validate that the Docker image loaded successfully:
+
[source,cli]
docker images
+
You should see a Docker image named `cvo_aws_ubuntu_image` with the `latest` tag, as shown in the following example:
+
----
REPOSITORY                            TAG        IMAGE ID       CREATED      SIZE
    cvo_aws_flexcache_ubuntu_image     latest    18db15a4d59c   2 weeks ago   1.14GB
----
+
NOTE: You can change the Docker image name if required. If you change the Docker image name, make sure to update the Docker image name in the `docker-compose-deploy` and `docker-compose-destroy` files.

== Step 3: Create environment variable files

At this stage, you must create two environment variable files. One file is for authentication of AWS Resource Manager APIs using the AWS access and secret keys. The second file is for setting environment variables to enable BlueXP Terraform modules to locate and authenticate AWS APIs.

.Steps 

. Create the `awsauth.env` file in the following location: 
+
`path/to/env-file/awsauth.env`
+
... Add the following content to the `awsauth.env` file:
+
access_key=<>
secret_key=<>
+
The format *must* be exactly as shown above.

. Add the absolute file path to the `.env` file.
+
Enter the absolute path for the `awsauth.env` environment file that corresponds to the `AWS_CREDS` environment variable.
+
`AWS_CREDS=path/to/env-file/awsauth.env`

. Navigate to the `cvo_aws_variable` folder and update the access and secret key in the credentials file.
+
Add the following content to the file:
+
aws_access_key_id=<>
aws_secret_access_key=<>
+
The format *must* be exactly as shown above.

== Step 4: Add Cloud Volumes ONTAP licenses to BlueXP or subscribe to BlueXP

You can add Cloud Volumes ONTAP licenses to BlueXP or subscribe to NetApp BlueXP - Cloud Manager in the AWS Marketplace. 

.Steps

. From the AWS portal, navigate to *SaaS* and select *Subscribe to NetApp BlueXP*. 
+
You can either use the same resource group as Cloud Volumes ONTAP or a different resource group.
. Configure the BlueXP portal to import the SaaS subscription to BlueXP.
+
You can configure this directly from the AWS portal.
+
You are redirected to the BlueXP portal to confirm the configuration.

. Confirm the configuration in the BlueXP portal by selecting *Save*. 

== Step 5: Create an external volume

You should create an external volume to keep the Terraform state files, and other important files persistent. You must make sure that the files are available for Terraform to run the workflow and deployments.

.Steps

. Create an external volume outside of Docker Compose:
[source,cli]
docker volume create <volume_name>
+
Example:
+
----
docker volume create cvo_aws_volume_dst
----
. Use one of the following options:
.. Add an external volume path to the `.env` environment file.
+
You must follow the exact format shown below. 
+
Format:
+
`PERSISTENT_VOL=path/to/external/volume:/cvo_aws`
+
Example:
`PERSISTENT_VOL=cvo_aws_volume_dst:/cvo_aws`

.. Add NFS shares as an external volume. 
+
Make sure that the Docker container can communicate with the NFS shares and that the correct permissions, such as read-write, are configured.
+
... Add the NFS shares path as the path to the external volume in the Docker Compose file, as shown below:
Format:
+
`PERSISTENT_VOL=path/to/nfs/volume:/cvo_aws`
+
Example:
`PERSISTENT_VOL=nfs/mnt/document:/cvo_aws`

. Navigate to the `cvo_aws_variables` folder.
+
You should see the following variable file in the folder:
+
* `terraform.tfvars`
* `variables.tf`

. Change the values inside the `terraform.tfvars` file according to your requirements. 
+
You must read the specific supporting documentation when modifying any of the variable values in the `terraform.tfvars` file. The values can vary depending on region, availability zones, and other factors supported by Cloud Volumes ONTAP for AWS Cloud Provider. This includes licenses, disk size, and VM size for single nodes and high availability (HA) pairs. 
+
All supporting variables for the Connector and Cloud Volumes ONTAP Terraform modules are already defined in the `variables.tf` file. You must refer to the variable names in the `variables.tf` file before adding to the `terraform.tfvars` file.

. Depending on your requirements, you can enable or disable FlexCache and FlexClone by setting the following options to `true` or `false`. 
+
The following examples enable FlexCache and FlexClone:
+
* `is_flexcache_required = true`
* `is_flexclone_required = true`

== Step 6: Deploy Cloud Volumes ONTAP for AWS

.Steps

. From the root folder, run the following command to trigger deployment: 
[source,cli]
docker-compose -f docker-compose-deploy.yml up -d
+
Two containers are triggered, the first container deploys Cloud Volumes ONTAP and the second container sends telemetry data to AutoSupport. 
+
The second container waits until the first container completes all of the steps successfully.

. Monitor progress of the deployment process using the log files:
+
[source,cli]
docker-compose -f docker-compose-deploy.yml logs -f 
+
This command provides output in real-time and captures the data in the following log files:
`deployment.log`
+ 
`telemetry_asup.log`
+
You can change the name of these log files by editing the `.env` file using the following environment variables:
+
`DEPLOYMENT_LOGS`
+
`TELEMETRY_ASUP_LOGS`
+
The following examples show how to change the log file names:
+
`DEPLOYMENT_LOGS=<your_deployment_log_filename>.log`
+
`TELEMETRY_ASUP_LOGS=<your_telemetry_asup_log_filename>.log`

.After you finish

You can use the following steps to destroy the temporary environment and clean up items that were created during the deployment process. 

.Steps

. If you deployed FlexCache, set the following option in the `terraform.tfvars` variable file, this cleans up FlexCache volumes and destroys the temporary environment that was created earlier. 
+
`flexcache_operation = "destroy"`
+
NOTE: The possible options are  `deploy` and `destroy`.

. If you deployed FlexClone, set the following option in the `terraform.tfvars` variable file, this cleans up FlexClone volumes and destroys the temporary environment that was created earlier. 
+
`flexclone_operation = "destroy"`
+
NOTE: The possible options are `deploy` and `destroy`.



