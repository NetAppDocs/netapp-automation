---
sidebar: sidebar
permalink: solutions/cvo-azure-burst-to-cloud.html
keywords: nbluexp automation catalog, netapp automation solutions, azure, burst to cloud
summary: "You can use this automation solution to deploy Cloud Volumes ONTAP for Azure using Terraform."
---

= Cloud Volumes ONTAP for Azure deployment using Terraform
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/

[.lead]
This article supports the NetApp Cloud Volumes ONTAP for Azure Automation Solution, which is available to NetApp customers from the BlueXP Automation Catalog. 

The Cloud Volumes ONTAP for Azure Automation Solution automates the containerized deployment of Cloud Volumes ONTAP for Azure using Terraform, enabling you to deploy Cloud Volumes ONTAP for Azure rapidly, without any manual intervention.

.Before you begin

* You must have the automation solution file packaged as `CVO_Azure_Deployment`. You can download the solution file at the BlueXP web user interface.
* You must install a Linux VM on the same network as Cloud Volumes ONTAP. 
* After you install the Linux VM, you must follow the steps in this solution to install the required dependencies. 

== Step 1: Install Docker and Docker Compose

=== Install Docker

The following steps use Ubuntu 20.04 Debian Linux distribution software as an example. The commands you use depend on the Linux distribution software that you are using. Refer to the specific Linux distribution software documentation for your configuration. 

.Steps

. Install Docker by running the following `sudo` commands: 
+
----
sudo apt-get update 
sudo apt-get install apt-transport-https cacertificates curl gnupg-agent software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | 
sudo apt-key add -
sudo add-apt-repository ‚Äúdeb [arch=amd64] https://download.docker.com/linux/ubuntu
$(lsb_release -cs) stable‚Äù 
sudo apt-get update 
sudo apt-get install dockerce docker-ce-cli containerd.io  
----

. Verify that the installation was successful:
+
[source,cli]
docker ‚Äìversion

. Check that a group named "docker" has been created on your Linux system. If necessary, create the group:
+
[source,cli]
sudo groupadd docker

. Add the user that needs to access Docker to the group:
+
[source,cli]
sudo usermod -aG docker $(whoami)

. Your changes take effect after you log out and log back in to the terminal. Alternatively, you can immediately implement the changes:
+
[source,cli]
newgrp docker

=== Install Docker Compose

.Steps 

. Install Docker Compose by running the following `sudo` commands:
+
----
sudo curl -L ‚Äúhttps://github.com/docker/compose/releases/download/1.29.2/dockercompose-(ùë¢ùëõùëéùëöùëí ‚àí ùë†)‚àí(uname -m)‚Äù -o /usr/local/bin/docker-compose

sudo chmod +x /usr/local/bin/docker-compose 
----
. Verify that the installation was successful: 
[source,cli]
docker-compose ‚Äìversion

== Step 2: Prepare the Docker image

.Steps
. Copy the `CVO_Azure_Deployment` folder to the VM that you want to use to deploy Cloud Volumes ONTAP:
+
[source,cli]
scp -i ~/<private-key>.pem -r CVO_Azure_Deployment <azureuser>@<IP_ADDRESS_OF_VM>:<LOCATION_TO_BE_COPIED>

* `private-key.pem` is your private key file for login without a password.
* `azureuser` is the VM username.
* `IP_ADDRESS_OF_VM` is the VM IP address.
* `LOCATION_TO_BE_COPIED` is the location where the folder will be copied.

. Extract the `CVO_Azure_Deployment.zip` folder. You can extract the folder in the current directory or in a custom location.
+
To extract the folder in the current directory, run:
+
[source,cli]
unzip CVO_Azure_Deployment.zip
+
To extract the folder in a custom location, run:
+
[source,cli]
unzip CVO_Azure_Deployment.zip -d ~/<your_folder_name>

. After you extract the folder, run the following command to view the files:
+
[source,cli]
 ls -la
+
You should see a list of files, similar to the following example:
+
----
drwxr-xr-x@ 11 user1 staff 352 May 5 13:56 .
drwxr-xr-x@ 5 user1 staff 160 May 5 14:24 ..
-rw-r--r--@ 1 user1 staff 324 May 5 13:18 .env
-rw-r--r--@ 1 user1 staff 1449 May 5 13:18 Dockerfile
-rw-r--r--@ 1 user1 staff 35149 May 5 13:18 LICENSE
-rw-r--r--@ 1 user1 staff 13356 May 5 14:26 README.md
-rw-r--r-- 1  user1 staff 354318151 May 5 13:51 cvo_azure_flexcache_ubuntu_image_latest
drwxr-xr-x@ 4 user1 staff 128 May 5 13:18 cvo_azure_variables
-rw-r--r--@ 1 user1 staff 996 May 5 13:18 docker-compose-deploy.yml
-rw-r--r--@ 1 user1 staff 1041 May 5 13:18 docker-compose-destroy.yml
-rw-r--r--@ 1 user1 staff 4771 May 5 13:18 sp_role.json
----

. Locate the `cvo_azure_flexcache_ubuntu_image_latest.tar.gz` file. This contains the Docker image required to deploy Cloud Volumes ONTAP for Azure.
+
Untar the file:
+
[source,cli]
docker load -i cvo_azure_flexcache_ubuntu_image_latest.tar.gz

. Wait a few minutes for the Docker image to load, and then validate that the Docker image loaded successfully:
+
[source,cli]
docker images
+
You should see a Docker image named `cvo_azure_flexcache_ubuntu_image_latest` with the `latest` tag, as shown in the following example:
+
----
REPOSITORY TAG IMAGE ID CREATED SIZE
cvo_azure_flexcache_ubuntu_image latest 18db15a4d59c 2 weeks ago 1.14GB
----

== Step 3: Create environment variable files

At this stage, you must create two environment variable files. One file is for the authentication of Azure Resource Manager APIs using service principal credentials. The second file is for setting environment variables to enable BlueXP Terraform modules to locate and authenticate Azure APIs.

.Steps 

. Create a service principal. 
+
Before you can create the environment variable files you must create a service principal by following the steps in link:https://learn.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal[Create an Azure Active Directory application and service principal that can access resources^].

. Assign the *Contributor* role to the newly created service principal.
. Create a custom role. 
+ 
.. Locate the `sp_role.json` file and check for the required permissions under the actions listed.
..  Insert these permissions and attach the custom role to the newly created service principal. 

. Navigate to *Certificates & secrets* and select *New client secret* to create the client secret. 
+
When you create the client secret, you must record the details from the *Value* column because you will not be able to see this value again. You must also record the following information:
+
* Client ID
* Subscription ID 
* Tenant ID 
+
You will need this information to create the environment variables. You can find client ID and tenant ID information in the *Overview* section of the Service Principal UI. 

. Create the environment files. 
.. Create the `azureauth.env` file in the following location: 
+
`path/to/env-file/azureauth.env`
+
... Add the following content to the file:
+
clientId=<> clientSecret=<> subscriptionId=<> tenantId=<>
+
The format *must* be exactly as shown above without any spaces between the key and value.

.. Create the `credentials.env` file in the following location:
+
`path/to/env-file/credentials.env`
+
... Add the following content to the file:
+
AZURE_TENANT_ID=<> AZURE_CLIENT_SECRET=<>
AZURE_CLIENT_ID=<> AZURE_SUBSCRIPTION_ID=<>
+
The format *must* be exactly as shown above without any spaces between the key and value.

. Add the absolute file paths to the `.env` file.
+
Enter the absolute path for the `azureauth.env` environment file in the `.env` file that corresponds to the `AZURE_RM_CREDS` environment variable.
+
`AZURE_RM_CREDS=path/to/env-file/azureauth.env`
+
Enter the absolute path for the `credentials.env` environment file in the `.env` file that corresponds to the `BLUEXP_TF_AZURE_CREDS` environment variable.
+
`BLUEXP_TF_AZURE_CREDS=path/to/env-file/credentials.env`


== Step 4: Add Cloud Volumes ONTAP licenses to BlueXP or subscribe to BlueXP

You can add Cloud Volumes ONTAP licenses to BlueXP or subscribe to NetApp BlueXP - Cloud Manager in the Azure Marketplace. 

.Steps

. From the Azure portal, navigate to *SaaS* and select *Subscribe to NetApp BlueXP*.
. Select the *Cloud Manager (by Cap PYGO by Hour, WORM and data services)* plan. 
+
You can either use the same resource group as Cloud Volumes ONTAP or a different resource group.
. Configure the BlueXP portal to import the SaaS subscription to BlueXP.
+
You can configure this directly from the Azure portal by navigating to *Product and plan details* and selecting the *Configure account now* option.
+
You will then be redirected to the BlueXP portal to confirm the configuration.

. Confirm the configuration in the BlueXP portal by selecting *Save*. 

== Step 5: Create an external volume

You should create an external volume to keep the Terraform state files and other important files persistent. You must make sure that the files are available for Terraform to run the workflow and deployments.

.Steps

. Create an external volume outside of Docker Compose:
[source,cli]
docker volume create ¬´ volume_name ¬ª
+
Example:
+
----
docker volume create cvo_azure_volume_dst
----
. Use one of the following options:
.. Add an external volume path to the `.env` environment file.
+
You must follow the exact format shown below. 
+
Format:
+
PERSISTENT_VOL=path/to/external/volume:/cvo_azure
+
Example:
`PERSISTENT_VOL=cvo_azure_volume_dst:/cvo_azure`

.. Add NFS shares as an external volume. 
+
Make sure that the Docker container can communicate with the NFS shares and that the correct permissions, such as read-write, are configured.
+
... Add the NFS shares path as the path to the external volume in the Docker Compose file, as shown below:
Format:
+
PERSISTENT_VOL=path/to/nfs/volume:/cvo_azure
+
Example:
`PERSISTENT_VOL=nfs/mnt/document:/cvo_azure`

. Navigate to the `cvo_azure_variables` folder.
+
You should see the following variable file in the folder:
+
`terraform.tfvars variables.tf`

. Change the values inside the `terraform.tfvars` file according to your requirements. 
+
You must read the specific supporting documentation when modifying any of the variable values in the `terraform.tfvars` file. The values can vary depending on region, availability zones and other factors supported by Cloud Volumes ONTAP for Azure Cloud Provider. This includes licenses, disk size, and VM size for single nodes and high availability (HA) pairs. 
+
All supporting variables for the connector and Cloud Volumes ONTAP Terraform modules are already defined in the `variables.tf` file. You must refer to the variable names in the `variables.tf` file before adding to the `terraform.tfvars` file.

. Depending on your requirements, you can enable or disable FlexCache and FlexClone by setting the following options to `true` or `false`. 
+
The examples shown below enable FlexCache and FlexClone:
+
* `is_flexcache_required = true`
* `is_flexclone_required = true`

. If necessary, you can retrieve the value for the Terraform `az_service_principal_object_id` variable from the Azure Active Directory Service:
.. Navigate to *Enterprise Applications ‚Äì> All Applications* and select the name of
the Service Principal you created earlier. 
.. Copy the object ID and insert the value for the Terraform variable:
+ 
`az_service_principal_object_id`

== Step 6: Deploy Cloud Volumes ONTAP for Azure

.Steps

. From the root folder, run the following command to trigger deployment: 
[source,cli]
docker-compose up -d
. Two containers are triggered, the first container deploys Cloud Volumes ONTAP and the second container sends telemetry data to AutoSupport. 
+
The second container waits until the first container completes all of the steps successfully.

. Monitor progress of the deployment process using the log files:
+
[source,cli]
docker-compose logs -f
+
This command provides output in real-time and captures the data in the following log files:
+
`deployment.log` 
+
`telemetry_asup.log`
+
You can change the name of these log files by editing the `.env` file using the following environment variables:
+
`DEPLOYMENT_LOGS`
+
`TELEMETRY_ASUP_LOGS`
+
The following examples show how to change the log file names:
+
`DEPLOYMENT_LOGS=<your_deployment_log_filename>.log`
+
`TELEMETRY_ASUP_LOGS=<your_telemetry_asup_log_filename>.log`

.After you finish

You can use the following steps to destroy the environment and clean up temporary that were created during the deployment process. 

.Steps

. If you deployed FlexCache, set the following option in the `terraform.tfvars` variable file, this cleans up FlexCache and destroys the temporary environment that was deployed earlier. 
+
`flexcache_operation = "destroy"`
+
NOTE: The possible options are  `deploy` and `destroy`.

. If you deployed FlexClone, set the following option in the `terraform.tfvars` variable file, this cleans up FlexClone and destroys the temporary environment that was deployed earlier. 
+
`flexclone_operation = "destroy"`
+
NOTE: The possible options are `deploy` and `destroy`.


